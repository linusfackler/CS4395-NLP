{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Assignment: WordNet\n",
    "\n",
    "Linus Fackler\n",
    "\n",
    "## WordNet\n",
    "WordNet is a lexical database that organizes English words based on their meanings and relationships with other words. It groups words into sets of synonyms called synsets, and each synset is linked to other synsets through semantic relationships such as hypernymy (broader term) and hyponymy (narrower term). WordNet has many applications in natural language processing and computational linguistics.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synsets of noun 'car'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('car')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a synset\n",
    "\n",
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car = wn.synset('car.n.01')\n",
    "car.definition()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he needs a car to get to work']"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.examples()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('car.n.01.car'),\n",
       " Lemma('car.n.01.auto'),\n",
       " Lemma('car.n.01.automobile'),\n",
       " Lemma('car.n.01.machine'),\n",
       " Lemma('car.n.01.motorcar')]"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.lemmas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traversing up the WordNet hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root hypernym: [Synset('entity.n.01')]\n",
      "\n",
      "10 highest nouns in hierarchy:\n",
      "Synset('entity.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('abstraction.n.06')\n",
      "Synset('thing.n.12')\n",
      "Synset('object.n.01')\n",
      "Synset('whole.n.02')\n",
      "Synset('congener.n.03')\n",
      "Synset('living_thing.n.01')\n",
      "Synset('organism.n.01')\n",
      "Synset('benthos.n.02')\n",
      "Synset('dwarf.n.03')\n"
     ]
    }
   ],
   "source": [
    "print(\"root hypernym:\", car.root_hypernyms())\n",
    "\n",
    "print(\"\\n10 highest nouns in hierarchy:\")\n",
    "i = 1\n",
    "for synset in list(wn.all_synsets('n')):\n",
    "    print(synset)\n",
    "    if i > 10:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "# car_synsets = wn.synsets('car', pos=wn.NOUN)\n",
    "# for sense in car_synsets:\n",
    "#     lemmas = [l.name() for l in sense.lemmas()]\n",
    "#     print(\"Synset: \" + sense.name() + \"(\" + sense.definition() + \") \\n\\t Lemmas:\" + str(lemmas))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that \"entity\" is at the top of the noun hierarchy.\n",
    "We traverse from car up to entity in the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('motor_vehicle.n.01')\n",
      "Synset('self-propelled_vehicle.n.01')\n",
      "Synset('wheeled_vehicle.n.01')\n",
      "Synset('container.n.01')\n",
      "Synset('instrumentality.n.03')\n",
      "Synset('artifact.n.01')\n",
      "Synset('whole.n.02')\n",
      "Synset('object.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "hyp = car.hypernyms()[0]\n",
    "top = wn.synset('entity.n.01')\n",
    "while hyp:\n",
    "    print(hyp)\n",
    "    if hyp == top:\n",
    "        break\n",
    "    if hyp.hypernyms():\n",
    "        hyp = hyp.hypernyms()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet organizes their nouns into hierarchies based on the hypernymy/hyponymy relation between synsets. The more we got up in the hierarchy, the more \"general\" the nouns get.\n",
    "\"Activity\" is a hypernym of \"car\", \"act\" a hypernym of \"activity\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('motor_vehicle.n.01'),\n",
       " Synset('self-propelled_vehicle.n.01'),\n",
       " Synset('wheeled_vehicle.n.01'),\n",
       " Synset('container.n.01'),\n",
       " Synset('vehicle.n.01'),\n",
       " Synset('instrumentality.n.03'),\n",
       " Synset('conveyance.n.03'),\n",
       " Synset('artifact.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('object.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper = lambda s: s.hypernyms()\n",
    "list(car.closure(hyper))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('ambulance.n.01'),\n",
       " Synset('beach_wagon.n.01'),\n",
       " Synset('bus.n.04'),\n",
       " Synset('cab.n.03'),\n",
       " Synset('compact.n.03'),\n",
       " Synset('convertible.n.01'),\n",
       " Synset('coupe.n.01'),\n",
       " Synset('cruiser.n.01'),\n",
       " Synset('electric.n.01'),\n",
       " Synset('gas_guzzler.n.01'),\n",
       " Synset('hardtop.n.01'),\n",
       " Synset('hatchback.n.01'),\n",
       " Synset('horseless_carriage.n.01'),\n",
       " Synset('hot_rod.n.01'),\n",
       " Synset('jeep.n.01'),\n",
       " Synset('limousine.n.01'),\n",
       " Synset('loaner.n.02'),\n",
       " Synset('minicar.n.01'),\n",
       " Synset('minivan.n.01'),\n",
       " Synset('model_t.n.01'),\n",
       " Synset('pace_car.n.01'),\n",
       " Synset('racer.n.02'),\n",
       " Synset('roadster.n.01'),\n",
       " Synset('sedan.n.01'),\n",
       " Synset('sport_utility.n.01'),\n",
       " Synset('sports_car.n.01'),\n",
       " Synset('stanley_steamer.n.01'),\n",
       " Synset('stock_car.n.01'),\n",
       " Synset('subcompact.n.01'),\n",
       " Synset('touring_car.n.01'),\n",
       " Synset('used-car.n.01'),\n",
       " Synset('funny_wagon.n.01'),\n",
       " Synset('shooting_brake.n.01'),\n",
       " Synset('gypsy_cab.n.01'),\n",
       " Synset('minicab.n.01'),\n",
       " Synset('panda_car.n.01'),\n",
       " Synset('berlin.n.03'),\n",
       " Synset('minicab.n.01'),\n",
       " Synset('finisher.n.05'),\n",
       " Synset('stock_car.n.02'),\n",
       " Synset('brougham.n.02')]"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo = lambda s: s.hyponyms()\n",
    "list(car.closure(hypo))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('accelerator.n.01'),\n",
       " Synset('air_bag.n.01'),\n",
       " Synset('auto_accessory.n.01'),\n",
       " Synset('automobile_engine.n.01'),\n",
       " Synset('automobile_horn.n.01'),\n",
       " Synset('buffer.n.06'),\n",
       " Synset('bumper.n.02'),\n",
       " Synset('car_door.n.01'),\n",
       " Synset('car_mirror.n.01'),\n",
       " Synset('car_seat.n.01'),\n",
       " Synset('car_window.n.01'),\n",
       " Synset('fender.n.01'),\n",
       " Synset('first_gear.n.01'),\n",
       " Synset('floorboard.n.02'),\n",
       " Synset('gasoline_engine.n.01'),\n",
       " Synset('glove_compartment.n.01'),\n",
       " Synset('grille.n.02'),\n",
       " Synset('high_gear.n.01'),\n",
       " Synset('hood.n.09'),\n",
       " Synset('luggage_compartment.n.01'),\n",
       " Synset('rear_window.n.01'),\n",
       " Synset('reverse.n.02'),\n",
       " Synset('roof.n.02'),\n",
       " Synset('running_board.n.01'),\n",
       " Synset('stabilizer_bar.n.01'),\n",
       " Synset('sunroof.n.01'),\n",
       " Synset('tail_fin.n.02'),\n",
       " Synset('third_gear.n.01'),\n",
       " Synset('window.n.02'),\n",
       " Synset('exhaust.n.02'),\n",
       " Synset('horn_button.n.01'),\n",
       " Synset('bumper_guard.n.01'),\n",
       " Synset('armrest.n.01'),\n",
       " Synset('doorlock.n.01'),\n",
       " Synset('hinge.n.01'),\n",
       " Synset('back.n.08'),\n",
       " Synset('headrest.n.01'),\n",
       " Synset('seat_belt.n.01'),\n",
       " Synset('inlet_manifold.n.01'),\n",
       " Synset('hood_ornament.n.01'),\n",
       " Synset('exhaust_manifold.n.01'),\n",
       " Synset('exhaust_pipe.n.01'),\n",
       " Synset('exhaust_valve.n.01'),\n",
       " Synset('silencer.n.02'),\n",
       " Synset('tailpipe.n.01'),\n",
       " Synset('pintle.n.01')]"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mero = lambda s: s.part_meronyms()\n",
    "list(car.closure(mero))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holo = lambda s: s.part_holonyms()\n",
    "list(car.closure(holo))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "antonyms = []\n",
    "\n",
    "for l in car.lemmas():\n",
    "    if l.antonyms():\n",
    "        antonyms.append(l.antonyms(0).name())\n",
    "\n",
    "print(antonyms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synsets of verb 'drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('drive.n.01'),\n",
       " Synset('drive.n.02'),\n",
       " Synset('campaign.n.02'),\n",
       " Synset('driveway.n.01'),\n",
       " Synset('drive.n.05'),\n",
       " Synset('drive.n.06'),\n",
       " Synset('drive.n.07'),\n",
       " Synset('drive.n.08'),\n",
       " Synset('drive.n.09'),\n",
       " Synset('drive.n.10'),\n",
       " Synset('drive.n.11'),\n",
       " Synset('drive.n.12'),\n",
       " Synset('drive.v.01'),\n",
       " Synset('drive.v.02'),\n",
       " Synset('drive.v.03'),\n",
       " Synset('force.v.06'),\n",
       " Synset('drive.v.05'),\n",
       " Synset('repel.v.01'),\n",
       " Synset('drive.v.07'),\n",
       " Synset('drive.v.08'),\n",
       " Synset('drive.v.09'),\n",
       " Synset('tug.v.02'),\n",
       " Synset('drive.v.11'),\n",
       " Synset('drive.v.12'),\n",
       " Synset('drive.v.13'),\n",
       " Synset('drive.v.14'),\n",
       " Synset('drive.v.15'),\n",
       " Synset('drive.v.16'),\n",
       " Synset('drive.v.17'),\n",
       " Synset('drive.v.18'),\n",
       " Synset('drive.v.19'),\n",
       " Synset('drive.v.20'),\n",
       " Synset('drive.v.21'),\n",
       " Synset('drive.v.22')]"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('drive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a synset\n",
    "\n",
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'operate or control a vehicle'"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive = wn.synset('drive.v.01')\n",
    "drive.definition()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive a car or bus', 'Can you drive this four-wheel truck?']"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive.examples()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('drive.v.01.drive')]"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive.lemmas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traversing up the WordNet hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root hypernym: [Synset('touch.v.01')]\n",
      "\n",
      "10 highest verbs in hierarchy:\n",
      "Synset('breathe.v.01')\n",
      "Synset('respire.v.02')\n",
      "Synset('respire.v.01')\n",
      "Synset('choke.v.01')\n",
      "Synset('hyperventilate.v.02')\n",
      "Synset('hyperventilate.v.01')\n",
      "Synset('aspirate.v.03')\n",
      "Synset('burp.v.01')\n",
      "Synset('force_out.v.08')\n",
      "Synset('hiccup.v.01')\n",
      "Synset('sigh.v.01')\n"
     ]
    }
   ],
   "source": [
    "print(\"root hypernym:\", drive.root_hypernyms())\n",
    "\n",
    "print(\"\\n10 highest verbs in hierarchy:\")\n",
    "i = 1\n",
    "for synset in list(wn.all_synsets('v')):\n",
    "    print(synset)\n",
    "    if i > 10:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, verbs are different than nouns when it comes to their hierarchy. There is not just one verb that covers all other verbs, basically is the root hypernym for everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('drive.v.01')\n",
      "Synset('operate.v.03')\n",
      "Synset('manipulate.v.02')\n",
      "Synset('handle.v.04')\n",
      "Synset('touch.v.01')\n"
     ]
    }
   ],
   "source": [
    "hyp = drive\n",
    "top = wn.synset('touch.v.01')\n",
    "while hyp:\n",
    "    print(hyp)\n",
    "    if hyp == top:\n",
    "        break\n",
    "    if hyp.hypernyms():\n",
    "        hyp = hyp.hypernyms()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it doesn't go much higher in the hierarchy after \"drive\".\n",
    "It ends on a different verb than most other vers do.\n",
    "This is completely different than for nouns, where every noun eventually reaches \"entity\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphy for \"drive\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base form of 'drive':  drive\n"
     ]
    }
   ],
   "source": [
    "print(\"Base form of 'drive': \", wn.morphy('drive'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb form of 'drive':  drive\n"
     ]
    }
   ],
   "source": [
    "print(\"Verb form of 'drive': \", wn.morphy('drive', wn.VERB))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjective form of 'drive':  None\n"
     ]
    }
   ],
   "source": [
    "print(\"Adjective form of 'drive': \", wn.morphy('drive', wn.ADJ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base form of 'drive':  drive\n"
     ]
    }
   ],
   "source": [
    "print(\"Base form of 'drive': \", wn.morphy('drive', wn.NOUN))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk import word_tokenize as tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting 2 similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example words\n",
    "word1 = 'drive'\n",
    "word2 = 'ride'\n",
    "\n",
    "# example sentences\n",
    "sent1 = 'Do you want to drive with me?'\n",
    "sent2 = 'Do you want to ride with me?'\n",
    "\n",
    "# tokenizing example sentences\n",
    "sent1_tok = tokenize(sent1)\n",
    "sent2_tok = tokenize(sent2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lesk algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:  ['Do', 'you', 'want', 'to', 'drive', 'with', 'me', '?']\n",
      "Lesk' selected Synset: Synset('drive.v.09')\n",
      "\n",
      "Sentence 2:  ['Do', 'you', 'want', 'to', 'ride', 'with', 'me', '?']\n",
      "Lesk' selected Synset: Synset('ride.n.02')\n"
     ]
    }
   ],
   "source": [
    "synset1 = lesk(sent1_tok, word1)\n",
    "print(\"Sentence 1: \", sent1_tok)\n",
    "print(\"Lesk' selected Synset:\", synset1)\n",
    "\n",
    "synset2 = lesk(sent2_tok, word2)\n",
    "print(\"\\nSentence 2: \", sent2_tok)\n",
    "print(\"Lesk' selected Synset:\", synset2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wu-Palmer similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.wup_similarity(synset1, synset2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I would have thought the opposite, 'drive' and 'ride' seem to be relatively dissimilar and only moderately related in the semantic hierarchy. They share some common characteristics/associations though, but they're not as closely related. This might be because 'ride' can have different meanings and I should have selected the words based on their description, rather than just the word itself, to get a better result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentiWordNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functionality\n",
    "\n",
    "SemiWordNet is an extension of WordNet that measures the strength and direction of semantic relationships between words, with information on uncertainty. It enhances WordNet by providing information about the degree of semantic relatedness between words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible use cases\n",
    "\n",
    "It helps with natural language processing tasks and is useful for researchers and developers. Specifically, if accuracte measures of semantic similarity are required. These include information retrieval (improving accuracy of search engines), text classification, sentiment analysis, and machine translation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting emotionally charged word\n",
    "emo_word = 'excitement'\n",
    "\n",
    "senti_syn = list(swn.senti_synsets(emo_word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polarity scores for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<exhilaration.n.01: PosScore=0.5 NegScore=0.5>\n",
      "Positive score =  0.5\n",
      "Negative score =  0.5\n",
      "Objective score =  0.0\n",
      "<excitement.n.02: PosScore=0.375 NegScore=0.25>\n",
      "Positive score =  0.375\n",
      "Negative score =  0.25\n",
      "Objective score =  0.375\n",
      "<excitation.n.03: PosScore=0.0 NegScore=0.0>\n",
      "Positive score =  0.0\n",
      "Negative score =  0.0\n",
      "Objective score =  1.0\n",
      "<agitation.n.04: PosScore=0.0 NegScore=0.0>\n",
      "Positive score =  0.0\n",
      "Negative score =  0.0\n",
      "Objective score =  1.0\n"
     ]
    }
   ],
   "source": [
    "for syn in senti_syn:\n",
    "    print(syn)\n",
    "    print(\"Positive score = \", syn.pos_score())\n",
    "    print(\"Negative score = \", syn.neg_score())\n",
    "    print(\"Objective score = \", syn.obj_score())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example sentence\n",
    "emo_sentence = \"Surrounded by love and beauty, she found true happiness.\"\n",
    "\n",
    "emo_sentence_tok = tokenize(emo_sentence)\n",
    "emo_sentence_tok = [t for t in emo_sentence_tok if t.isalpha()]\n",
    "# punctuation is unnecessary for this example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polarity scores for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surrounded\n",
      "Positive score =  0.0\n",
      "Negative score =  0.0\n",
      "Objective score =  1.0\n",
      "\n",
      "by\n",
      "Positive score =  0.0\n",
      "Negative score =  0.0\n",
      "Objective score =  1.0\n",
      "\n",
      "love\n",
      "Positive score =  0.625\n",
      "Negative score =  0.0\n",
      "Objective score =  0.375\n",
      "\n",
      "and\n",
      "No score available\n",
      "\n",
      "beauty\n",
      "Positive score =  0.5\n",
      "Negative score =  0.0\n",
      "Objective score =  0.5\n",
      "\n",
      "she\n",
      "No score available\n",
      "\n",
      "found\n",
      "Positive score =  0.0\n",
      "Negative score =  0.0\n",
      "Objective score =  1.0\n",
      "\n",
      "true\n",
      "Positive score =  0.5\n",
      "Negative score =  0.0\n",
      "Objective score =  0.5\n",
      "\n",
      "happiness\n",
      "Positive score =  1.0\n",
      "Negative score =  0.0\n",
      "Objective score =  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in emo_sentence_tok:\n",
    "    print(t)\n",
    "    syn = list(swn.senti_synsets(t))\n",
    "    if (syn != []):\n",
    "        print(\"Positive score = \", syn[0].pos_score())\n",
    "        print(\"Negative score = \", syn[0].neg_score())\n",
    "        print(\"Objective score = \", syn[0].obj_score())\n",
    "    else:\n",
    "        print(\"No score available\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some scores that seem like they would be 100% positive, like 'beauty', are not. This might be because the context can affect these words specifically a lot. 'Love', for example, is mostly positive.\n",
    "'Surrounded' is neutral for obvious reasons.\n",
    "'Happiness' is completely positive, as even context can't completely change the meaning of the word.\n",
    "\n",
    "Knowing these scores is crucial for technologies like chatbots, for example. Sentences and words' objectiveness is different in every scenario and affects the overall meaning of what a person wants the machine to understand."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Collocation?\n",
    "\n",
    "Collocation refers to the frequent appearance of certain words together in a language, indicating a strong tendency for those words to be used in a particular combination.\n",
    "Collocation can help language learners understand how words are commonly used together and how to use them in context. It can also aid in natural language processing tasks, such as machine translation and text generation, by helping to ensure that words are used in a way that is consistent with the way they are used in natural language."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import text4\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text 4 Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "text4.collocations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select collocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Federal', 'Government')"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = text4.collocation_list()[4]\n",
    "coll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Federal Government) =  0.0031920199501246885\n",
      "p(Federal) =  0.006483790523690773\n",
      "p(Government) =  0.03371571072319202\n",
      "pmi =  3.868067366919006\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(text4.tokens)\n",
    "\n",
    "vocab = len(set(text4))\n",
    "hg = text.count(coll[0] + \" \" + coll[1]) / vocab\n",
    "print(\"p(\" + coll[0] + \" \" + coll[1] + \") = \", hg)\n",
    "\n",
    "h = text.count(coll[0]) / vocab\n",
    "print(\"p(\" + coll[0] + \") = \", h)\n",
    "\n",
    "g = text.count(coll[1]) / vocab\n",
    "print(\"p(\" + coll[1] + \") = \", g)\n",
    "\n",
    "pmi = math.log2(hg / (h * g))\n",
    "print(\"pmi = \", pmi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that those 2 words tend to be of relatively high collocation. Meaning they will appear together more likely than expected when randomly throwing words together."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example run 2 - collocation\n",
    "\n",
    "Just to be able to compare this to another result, I will run this again on a different set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vice', 'President')"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll2 = text4.collocation_list()[7]\n",
    "coll2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Vice President) =  0.0017955112219451373\n",
      "p(Vice) =  0.0018952618453865336\n",
      "p(President) =  0.010773067331670824\n",
      "pmi =  6.458424602064904\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(text4.tokens)\n",
    "\n",
    "vocab = len(set(text4))\n",
    "hg = text.count(coll2[0] + \" \" + coll2[1]) / vocab\n",
    "print(\"p(\" + coll2[0] + \" \" + coll2[1] + \") = \", hg)\n",
    "\n",
    "h = text.count(coll2[0]) / vocab\n",
    "print(\"p(\" + coll2[0] + \") = \", h)\n",
    "\n",
    "g = text.count(coll2[1]) / vocab\n",
    "print(\"p(\" + coll2[1] + \") = \", g)\n",
    "\n",
    "pmi = math.log2(hg / (h * g))\n",
    "print(\"pmi = \", pmi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the pmi is higher, meaning, those 2 words appear even more frequent together.\n",
    "This seems like obvious information for humans, since 'Vice' and 'President' are heard together often.\n",
    "But for a machine to recognize this information makes NLP and its application even more superior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
